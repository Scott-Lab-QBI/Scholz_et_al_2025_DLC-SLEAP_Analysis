# Post tracking analysis (MATLAB and Python)
## Automated behavioral tracking of zebrafish larvae with DeepLabCut and SLEAP: pre-trained networks and datasets of annotated poses 
Leandro A. Scholz, Tessa Mancienne, Sarah J. Stednitz, Ethan K. Scott, Conrad C.Y. Lee\
bioRxiv DOI: [10.1101/2025.06.04.657938](https://doi.org/10.1101/2025.06.04.657938)\
\
Please refer to our repository for DeepLabCut and SLEAP pre-trained models:\
**Scholz LA, Lee C, Stednitz S, Mancienne T, Scott E** (2025) *DLC and SLEAP pre-trained exported models.* The University of Melbourne. Software. DOI: [10.26188/29275838](https://doi.org/10.26188/29275838) 

We also provide the annotated datasets used to train and compare the models, which can be downloaded from:\
**Scholz LA, Mancienne T, Stednitz S, Scott E, Lee C** (2025) *Datasets of zebrafish larvae poses - annotated frames and videos.* Dataset. DOI: [10.26188/29276009.v1](https://doi.org/10.26188/29276009.v1) 

# Instructions for MATLAB Implementation
1. Generate directory and clone MATLAB analysis package to C:/toolbox/dlc_analysis
2. In dlc_analysis, demo_script.m provides an example script to analyse h5 files generated by DeepLabCut as described [here.](https://github.com/Scott-Lab-QBI/zf_tracking_networks)
3. There are several parameters that users should define:

| Variables | Usage|
| :------- | :------ |
| **body_center_parts** | Tracked body part/s is selected to determine where the center is. Selection of more than 1 part results in averaged location.|
| **thr** | Selection of threshold to reject poor tracking confidence.|
| **frame_rate** | Video acquisation frame-rate to convert calculations into seconds.|
| **smooth_val** | Value for smoothing.|
| **pxl_resolution** | This allows conversion of pixel to mm. Especially useful for speed/accerlation plots.|
| **tolerance** | Allows user to remove noisy signals.|\



5. Parameters for bout detection are video and tracking quality dependent. <ins> We advise users to use this with caution! </ins> Bout detection is determined by peak-detection and these parameters determine the sensitivity. We advise users to check how well bout detection works on their own dataset first by visually checking against speed and tail angle plots.\
6. The core functions are: get_body_center, get_point_metrics, get_vector_metrics, get_bout_metrics. Each functions has individual help comments if users need additional explainations.\
7. Looking at demo_script.m, you will find basic plots for a 6s recording of a 6dpf fish.\

# Instruction for PYTHON Implementation

`zf_track_analysis` is a Python package for analyzing the behavior of larval zebrafish from pose-estimation data. It processes tracking results from DeepLabCut (DLC) or SLEAP, computes a rich set of frame-by-frame kinematic metrics, detects swim bouts, and calculates detailed per-bout metrics.

## Features

- **Comprehensive Kinematics**: Computes position, velocity, acceleration, heading, tail curvature, and more.
- **Bout Detection**: Detects the onset and offset of swim bouts based on movement and tail dynamics.
- **Detailed Bout Metrics**: For each bout, calculates over 20 metrics including duration, distance, speed, vigor, symmetry, and tail beat frequency.
- **Flexible Input**: Natively supports HDF5 files from both DeepLabCut and SLEAP.
- **Highly Configurable**: All analysis parameters are managed through a single, easy-to-edit `config.yaml` file.
- **Reproducible Outputs**: Saves processed dataframes (`ethogram` and `bouts`) to HDF5 files for easy access and downstream analysis.

## Installation

1.  **Clone the repository:**
    ```bash
    git clone <your-repository-url>
    cd Scholz_et_al_2025_DLC_Analysis/Python
    ```

2.  **Set up a Python environment:**
    It is recommended to use a virtual environment. You could use conda to create it.
    ```bash
    conda create -n zf_track_analysis python=3.10
    ```
    Then activate it by calling 
    ```bash
    conda activate zf_track_analysis
    ```

3.  **Install dependencies:**
    The required packages are listed in `requirements.txt`.
    ```bash
    pip install -r requirements.txt
    ```
4. **Run demo using ``demo_dlc_output.h5`` file:** On the command prompt, make sure you the working directory is changed to the `examples`. 
   ```
   cd examples
   ```
   Then you can run the demo. 

   ```bash
   python run_demo.py --config config.yaml
   ```
   The demo will only run if you execute pyhton from the examples folder, as the ``config.yaml`` file gives the relative path where the ``demo_dlc_output.h5``is located, but if you want you can change that in ``config.yaml`` file so it has an absolute path to the demo.

## Using as a Library

Beyond running the provided demo and notebook, you can import `zf_track_analysis` into your own Python scripts or Jupyter notebooks to use its functions. Since the package is used locally and not installed from PyPI, you must first add the project's `src` directory to your Python path.

## Using as a Library
Beyond running the provided demo, you can import `zf_track_analysis` into your own Python scripts or Jupyter notebooks to use its functions. Since the package is used locally and not installed from PyPI, you must first add the project's `src` directory to your Python path.

### In a Python Script (.py)
To import `zf_track_analysis` in your own script, you need to tell Python where to find it by adding its `src` directory to `sys.path`.
 
#### Case 1: Your script is inside the project directory
If your script is located within the project structure (e.g., in a new `analysis/` folder), you can use a relative path based on the script's location to find the `src` directory.

```python
import sys
from pathlib import Path

# Add the project's src directory to the Python path
# This example assumes your script is in a subfolder of the 'Python' directory
project_root = Path(__file__).resolve().parent.parent
src_path = project_root / 'src'

if str(src_path) not in sys.path:
    sys.path.append(str(src_path))

# Now you can import and use the library's functions
import zf_track_analysis

# example_df = zf_track_analysis.get_all_metrics(...)
```

#### Case 2: Your script is in an external directory 
If your script is located outside of the project folder, you must provide an absolute path to the project's src directory. 
```python 
import sys 
from pathlib import Path 
# Provide the absolute path to the 'src' directory of the zf_track_analysis project. 
# IMPORTANT: Replace this with the actual path on your system. 
src_path = Path("C:/path/to/your/cloned/repo/Scholz_et_al_2025_DLC_Analysis/Python/src") 

if str(src_path) not in sys.path:
    sys.path.append(str(src_path))

# Now you can import and use the library's functions 
import zf_track_analysis 
#... your code ... 
```

### In a Jupyter Notebook (.ipynb)

In a Jupyter notebook, `__file__` is not defined, so you should use a relative or absolute path to the `src` directory.

```python
# In a notebook cell
import sys
from pathlib import Path

# Provide the path to the 'src' directory relative to your notebook
src_path = Path('../src') # Or use an absolute path

if str(src_path) not in sys.path:
    sys.path.append(str(src_path))

# Now you can import the library
import zf_track_analysis
```

---


## Usage

The entire analysis pipeline is run from a single script, `run_demo.py`, which is configured by a YAML file. These instructions now are if you want to run the workflow for your own videos (NOT ``demo_dlc_output.h5``) 

### 1. Configure the Analysis

Before running, you must edit the `examples/config.yaml` file to match your experiment and data. This is the most critical step.

```yaml
# examples/config.yaml

# --- File Path Configuration ---
# Path to the folder containing the .h5 tracking files from DLC/SLEAP.
tracking_folder_path: "C:\\Users\\lscholz\\Downloads\\Examples" 

# -- Result type configuration --
# either 'DLC' or 'SLEAP'
result_type: 'DLC'
result_pattern: 'DLC_resnet152_ZF-RoscoSep13shuffle1_5400000'

# --- Experiment Metadata ---
# These values are used to convert pixels to physical units and frames to time.
experiment_specs:
  resolution_mmpx: 0.06  # Spatial resolution in millimeters per pixel.
camera_specs:
  frame_rate: 300        # Video frame rate in frames per second (FPS).
  width: 254             # Width of the video frame in pixels.

# --- Bodypart Definitions ---
# Defines which keypoints are used for different calculations.
bodyparts_dict:
  # List of keypoints to average for calculating the center of the body.
  point_metrics:
    - 'L_eye_top'
    - 'R_eye_top'
    - 'L_eye_bottom'
    - 'R_eye_bottom'
    - 'swim_bladder'
  # Defines the heading vector.
  # First list: keypoint(s) for the vector origin.
  # Second list: keypoint(s) for the vector tip.
  vector_metrics:
    - ['swim_bladder']
    - ['L_eye_top', 'R_eye_top', 'L_eye_bottom', 'R_eye_bottom']

# --- Function-specific Parameters ---

# Parameters for get_all_metrics()
metrics_params:
  pcutoff: 0.8             # Likelihood threshold from pose estimation to consider a point valid.
  px_tolerances: [0.15, 60]  # Min/max pixel distance change between frames to be considered valid movement.
  point_movavg: 7          # Window size (frames) for moving average on point metrics (e.g., position).
  vector_smooth: 9         # Window size (frames) for Savitzky-Golay filter on vector metrics (e.g., heading).
  truncate_tail_pts: 9     # Number of tail points (from base) to use for tail curvature metrics.

# Parameters for bout_detector()
bout_detection_params:
  smooth_window: 5              # Window size (frames) for smoothing distance signal before peak detection.
  min_peak_separation: 0.1667   # Minimum time in seconds between bouts.
  min_peak_prominence: 0.01     # Minimum prominence of a peak to be considered a valid bout.
  num_repeats: 7                # Num consecutive frames of low movement to define start/end of a bout.

# Parameters for compute_bout_metrics()
bout_metrics_params:
  smooth_point: ['mean', 30]
  smooth_vector: ['mean', 10]
  smooth_vigor_window: 44
  end_time: 6                   # End time in seconds for calculating the IBI of the final bout.
```
### 2. Run the Script

Once the `config.yaml` file is set up, run the analysis from the command line (the command below assumes you are currently in the repo\Python folder):

```bash
python examples/run_demo.py --config examples/config.yaml
```

The script will search for files matching the `result_pattern` in the `tracking_folder_path`, process each one, and save the results.

---

## Output Files

For each input file (e.g., `my_video.h5`), the script generates two output files in the same directory:

1.  **`my_video_ethogram.h5`**: Contains the `all_metrics` DataFrame with frame-by-frame kinematic data. This is useful for plotting time-series data.
2.  **`my_video_bouts.h5`**: Contains the `bouts_df` DataFrame with detailed metrics for each detected swim bout. This is the primary output for swim bout-based analysis of behaviour.

## Project Structure

```
Python/
├── examples/
│   ├── run_demo.py         # Main script to execute the analysis
│   └── config.yaml         # Configuration file for all parameters
├── src/
│   └── zf_track_analysis/
│       ├── __init__.py     # Makes the directory a Python package
│       ├── core.py         # High-level functions (get_all_metrics, bout_detector, etc.)
│       └── utils.py        # Low-level helper functions (derivatives, geometry, etc.)
├── README.md               # This file
└── requirements.txt        # Python dependencies
```

## License
This project is licensed under the MIT License. See the `LICENSE` file for details.


### Disclaimer

Despite our best efforts to code the workflow as similar as possible, the Matlab and Python implementations are NOT THE SAME. We tested a few videos and verified that results match very closely, but are not the same. 
